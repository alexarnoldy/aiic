## Embedded SUSE Harvester Application Modernization

### The Challenge

* *Most application and integrated solutions providers rely on legacy, monolithic applications* that currently provide significant revenue for their business.

* *Most virtualization and Kubernetes platforms do not allow for modernizing* monolithic applications into microservices through a safe, iterative design process.

* *Legacy virtualization platforms are dependent on decades old technology.*

* *Solution providers want to modernize their legacy applications*, but they don't have the time or resources to completely rebuild their applications into a microservice architecture. 

* *There is significant risk associated with completely replacing* an active, legacy application with a re-architected implementation.

### Architectural Overview

This design leverages many SUSE technologies. These include: 
* SUSE Rancher as a central point of management, automation, and administration for all virtualization and containerization platforms 
* SUSE Harvester as a Kubernetes based, Hyper-Converged Infrastructure, type 1 hypervisor 
* SUSE Linux Enterprise 15 and SLE Micro as the virtual machine operating systems 
** As a fully Hyper-Converged Infrastructure hypervisor, Harvester provides its workloads virtualization, storage, and network resources without additional investment.
* K3s as the Kubernetes distribution to run containerized workloads 
* SUSE Base Container Image as the Enterprise ready, fully supportable application platform.

The goal of this design is to provide a virtualization and Kubernetes platform that allows solution providers to seamlessly provide their legacy applications to customers while updating them into a microservice architecture. This SUSE, best-in-class platform allows providers to run their applications in a hybrid, virtualized plus containerized mode of operation. 

With this hybrid compute platform, the portions of an application stack that are not currently containerized run inside virtual machines. Both persistent and immutable virtual machines are supported. Immutable virtual machines are designed to run portions of an application stack that are not ready to be containerized and do not need to persist data locally. Leveraging immutable virtual machines can be used as a great first step in modernizing portions of an existing application stack. They can be operated in a mode similar as Kubernetes pods (e.g., restricted to a specific namespace, created and destroyed at will, etc.), while the services running inside the immutable VM retain the legacy application architecture.

One of the key differentiators of SUSE Harvester and other Hyper-Converged Infrastructure solutions is that Harvester, its virtual machines, as well as the K3s Kubernetes clusters can be fully managed by a single SUSE Rancher server. This allows an application development team to apply principles of automation uniformly by calling the Rancher server API for all infrastructure needs.

For the highest level of reliability, the design leverages three virtualization focused servers. The server's CPU, memory, storage, and network capacity can be tailored to the needs of the workload. The minimum recommended per node configuration is eight CPU cores, 32 GB of RAM, 120GB of SSD or NVMe storage, and 1Gb/s network. This configuration works well where the workload is small and predictable. Increasing each node's capacity to 16 CPU cores, 64GB of RAM, 500GB of SSD/NVMe storage and a 25Gb/s network significantly increases the solution's ability to handle heavier and variable workloads.

Dedicating three nodes to a solution can sometimes be a challenge for remote environments, however this gives the solution the maximum availability and reliability, plus allows for full lights-out management. The solution can also be used in a two node configuration, but with a reduction in availability and reliability. It would also require additional on-site technical assistance to recover from major server failures. 

Absent major hardware or software failures, the two and three node designs operate exactly the same. In the two node configuration, one node would maintain the RKE2 Kubernetes control-plane and etcd datastore as well as run virtual machines. The second node would only run virtual machines. Maintaining frequent backups of the etcd database is required to ensure recoverability in the event of a major failure of the node hosting the control plan and etcd datastore.

The journey towards modernizing the application is further made easier when using SUSE's Base Container Image (BCI). BCI offers developers a suite of secure, supported, flexible container images to build modern applications on. SUSE's BCI even includes a version that allows containerized applications to interface directly with systemd of the host system. Each SUSE BCI has full access to the SUSE software repositories with, or without, a support contract. Of course, protecting your applications with a support contract ensures the highest levels of availability and the fastest time to resolution for any unforeseen issues that might occur.


### The Solution

* *There is often resistance and even some fear around rebuilding*, from the ground up, the company's top money maker. Such an undertaking can incur a huge cost burden, represent a significant risk and interruption for customers. Often the task can seem so daunting that the attitude of "if it isn't broken..." can prevail. However, updating a legacy application to take advantage of microservices and Kubernetes can massively improve the application's reliability and availability. As well, a well architected microservice focused application can scale many times better than its antiquated cousin at the same time significantly reducing development, maintenance, and support costs.


* *One of the biggest hurdles to modernizing legacy applications* is that mode 1 technologies, such as virtual machines don't offer any means to help redevelop an application into a microservices architecture. Unfortunately, Kubernetes also offers nothing in the way to a pathway to reach the same goal. What Harvester brings to this particular table is the ability to run virtual machines in a Kubernetes context. This creates "stepping stones" for developers to begin updating their mode 1 applications. The initial steps can be to split the application into multiple VMs running in different namespaces. This introduces the ability to work with differing levels of network, storage, IPC, and process isolation; but doesn't require any other Kubernetes specific modifications. Just this one capability addresses the toughest challenge in modernizing an application, which is splitting up a monolithic application into semi-independent components without impacting the application's performance or capabilities. 

Harvester also allows application and solution providers to roll out these changes to their customers as a multi-step, iterative process rather than using the mode 1 practice of replacing the legacy application with a single, completely rebuilt product. Maintaining applications through Continuous Delivery processes is also one of the most important tenants of a microservices architecture.


* *Legacy virtualization platform providers are struggling to stay relevant in the cloud-native computing era.* They have held on to their highly profitable vendor lock-in strategies as long as possible but are now finding increasingly difficult to offer the value today's customers need. Building Kubernetes clusters on antiquated virtualization platforms only serves to extend the long standing tradition of vendor lock-in, while hobbling the true power of modern compute and containerization technologies. Virtual machines still have a big part to play in the modern IT landscape, however running virtual machines on a cutting edge Kubernetes-based platform unleashes previously unimagined potential for interoperability between virtual machines and containerized workloads.


* *SUSE Harvester provides compute, network, and storage in a physical footprint* that is often identical or smaller than the requirements of a highly available, legacy application. This allows solution providers to start with a single migration to the Harvester virtual machines, which is often very easy and transparent to their customers. As the solution provider builds experience with Kubernetes and microservices, they can roll out incremental updates to their customers that slowly move application components to the highly available K3s Kubernetes cluster that also runs on Harvester.


* *Harvester provides highly available virtualized and containerized infrastructures* so the application can be rebuild into microservices over time and over many, incremental updates. This significantly lowers the risks inherent to rebuilding a legacy application because it allows developers to tackle the easiest-to-containerize parts of the application first. Over time, and with more experience under their belts, they can continue to modernize the application, moving more and more components from the virtual machine(s) environment to the Kubernetes environment. Solution providers who are able to update their software in intelligent, incremental steps are able to secure very high customer confidence and can ensure the updates are compatible with the customer's environment and their needs.